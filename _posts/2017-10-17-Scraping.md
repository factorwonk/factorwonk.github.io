---
layout: post
title: Webscraping for predictive features of car sales
---

**Webscraping** <br />  <br />  Like similar online automobile sales websites, <https://www.carsales.com.au> allow prospective car buyers in Australia to view second hand car sales from private sellers and/or dealerships. Car sales are organized by state, seller and car type among other features. The well structured website makes it a suitable candidate for scraping using Python's [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) library after which we can test whether car sales prices can be predicted using scraped features. We use Natural Language Processing courtesy of Python's [nltk](http://www.nltk.org/) library to determine whether any words in the seller's description of the car are more or less helpful in predicting car price.

I scrape for the most popular car brands sold in NSW, Australia:

1. Toyota
2. Mazda
3. BMW
4. Volkswagen
5. Ford
6. Audi
7. Volvo

and my features of interest include:

* Number of Doors
* Number of Seats
* Engine Size
* Number of Cylinders
* Seller description
* Age of car
* Vehicle Type
* Mileage

which I save in a pandas dataframe. The distribution of car sales appears to follow a lognormal distribution, so I take the log of sales price instead which follows a normal distribution:

*Figure 1: Log Sales Price of NSW Car Sales*

![_config.yml]({{ site.baseurl }}/images/carsalesdist.png)

Using quantitative features scraped from the website, we arrive at an R-square of 79% which is pretty good in terms of explanatory power.

Complete notebook available [here](https://github.com/factorwonk/Portfolio/blob/master/carsales-scraper-full.ipynb)

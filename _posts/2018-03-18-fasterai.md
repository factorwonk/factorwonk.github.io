---
layout: post
title: Fast(er) ai
---

**Jeremy Howard's fast.ai Study Group, 2018** <br /> <br /> In February, I was invited by Sydney Machine Learning's [Paul Conyngham](https://twitter.com/paul_conyngham), to join a Saturday morning study group to tackle the first seven weeks of Jeremy Howard's [fast.ai](http://course.fast.ai/start.html) **Deep Learning for Coders** MOOC, under the kind auspices of [The Domain Group](https://www.domain.com.au/). I was excited to be part of the study group, as the course came highly recommended by my mentor [Greg Baker](https://www.linkedin.com/in/solresol/). 

In this ongoing post I will try to document everything I learned. While we studied the material together, the Jupyter notebooks here represent **my own work** at extending concepts covered in the MOOC with [kaggle](https://www.kaggle.com) sourced datasets and competitions.

**Week 1: Facial Recognition Classifier - Tony Stark or Elon Musk?**<br /> <br />Robert Downey Jr reinvigorated his career with his portrayal of Tony Stark in [Marvel's Iron Man (2008)](http://marvel.com/movies/movie/19/iron_man) movies. A little known fact is that Downey (hereafter: RDJ) based his portrayal of the genious, billionaire, playboy, philanthropist on serial entrepreneur [Elon Musk](https://www.theguardian.com/technology/2018/feb/09/elon-musk-the-real-life-iron-man). I wanted to use a Convolutional Neural Network, trained on [ImageNet data](https://en.wikipedia.org/wiki/ImageNet) to train a single label image classification model to distinguish between photos of RDJ and Elon Musk.

The input for this convolutional neural network will be photos of Elon Musk and Robert Downey Jr. Each photo will be transformed into a **rank 3 tensor** with dimensions *height x width x 3* where 3 represents each of the Red, Blue and Green channels that combine to form a pixel color. Each pixel in an image will have a value from 0 (black) to 255 (white).

Our output activation layer for this Convolutional Neural Network will be a sigmoid function which transforms the result of the previous layer into a **0** (RDJ) or **1** (Musk) classification, based on a preset threshold. Here we use the threshold 0.5, meaning that any image which is processed by the penultimate layer of our CNN and has an output value greater than or equal to 0.5 will be assigned to Musk otherwise Downey.

*Figure 1: Rank Tensor 3 representation of Elon Musk's photo*

![_config.yml]({{ site.baseurl }}/images/elonmuskimage.png)

I use the [Resnet34](https://arxiv.org/abs/1512.03385) architecture for facial recognition, trained for 10 epochs with a learning rate = 0.01, pre-trained on the ImageNet database. The learning rate is a hyperparameter representing how quickly or how slowly we want to update the weights of our model.

A first pass using this model reveals the images that the architecture is more sure about

![_config.yml]({{ site.baseurl }}/images/elonmuskmoresure.png)

and the images it's not quite so sure about. Note that the architecture seems to be having a tougher time identifying Elon as opposed to Downey. The model has an accuracy of around 70%.

![_config.yml]({{ site.baseurl }}/images/elonmusklesssure.png)

We're going to make a few quick improvements to the Resnet30 model by:

1. Changing the learning rate - this is our key hyperparameter
2. Augmenting the data

In order to determine the ideal learning rate, we use the he technique developed in the 2015 paper [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/abs/1506.01186), where we keep increasing the learning rate from a very small value, until the loss stops decreasing. We can plot the learning rate across batches to see what this looks like.

*Figure 2: Chart of Learning Rate*

![_config.yml]({{ site.baseurl }}/images/elonmusklr.png)

For our untrained model, we start with a learning rate = 0.001 at which point the loss is clearly improving and not yet at a minimum. Simply changing the learning rate and training for more epochs will result in overfitting.  One way to fix this is to effectively create more data, through data augmentation. This refers to randomly changing the images in ways that shouldn't impact their interpretation, such as horizontal flipping, zooming, and rotating.

*Figure 3: Augmenting the Images*

![_config.yml]({{ site.baseurl }}/images/elonmuskaugmentation.png)

This is similar to bootstrapping where we create new pieces of data using the same distribution of the original data. Now we re-train the model using our new learning rate and by adding our augmented data with the training model. Training over 10 epochs we get to an accuracy of 95%. The confusion matrix below shows that our model is now getting all photos of Robert Downey Jr correct in the test set and is only tripping up on a single photo of Elon Musk.

*Figure 4: Confusion Matrix shows accuracy of Binary Image Classifier*

![_config.yml]({{ site.baseurl }}/images/elonmuskconfusionmatrix.png)

----
****

The complete notebook for the Single Label Image Classifier is available [here](https://github.com/factorwonk/fastai/blob/master/adas-lesson1-genius-billionaire-playboy-philanthropist.ipynb)

----
****

**Week 2: Multi-Label Classification - Breaking into the Top 20% of the Kaggle Seedlings Competition**<br /> <br />While the previous Resnet34 model was used for single label classification, a slight variation of the architecture - ResNet50 is used for a multi-label classification [Kaggle](https://www.kaggle.com/c/plant-seedlings-classification) problem.

----
****

The complete notebook for the Multi-Label Image Classifier is available [here](https://github.com/factorwonk/fastai/blob/master/adas-lesson2-seedlings-final.ipynb)

----
****
